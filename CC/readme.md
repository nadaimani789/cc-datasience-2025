# üìä Analyse Machine Learning - Dataset Bank Marketing UCI

## üéØ Introduction
**Contexte** : Campagnes de marketing direct d'une banque portugaise (mai 2008-novembre 2010) via appels t√©l√©phoniques pour promouvoir des d√©p√¥ts √† terme.  
**Probl√©matique** : Pr√©dire si un client souscrira (`y = yes/no`).  
**Dataset** : 41,188 observations √ó 20 variables + cible binaire.  
**Objectif** : D√©velopper un mod√®le pr√©dictif performant pour optimiser le ciblage.

## üîß M√©thodologie

### Pr√©processing
- **Nettoyage** : Suppression doublons, gestion `unknown` comme valeurs manquantes
- **Encodage** : Ordinal (`education`), Label Encoding (binaires), One-Hot (multi-classes)
- **Normalisation** : `StandardScaler` (exclut `duration` - data leakage)
- **Feature Engineering** : `contact_ratio`, `previously_contacted`, `age_group`, `campaign_intensity`

### Mod√©lisation
| Algorithme | Justification |
|------------|---------------|
| **R√©gression Logistique** | Simple, interpr√©table, rapide |
| **Random Forest** | Robuste, g√®re non-lin√©arit√©, feature importance |
| **XGBoost** | √âtat-de-l'art, r√©gularisation, haute performance |

**Gestion d√©s√©quilibre** : SMOTE (oversampling)  
**Validation** : Train/Test 80/20 + Cross-Validation 5-fold  
**Optimisation** : `RandomizedSearchCV` (50 it√©rations)

## üìà R√©sultats & Discussion

### Performances Mod√®les de Base
Dataset: 41k observations fortement d√©s√©quilibr√© (~88% 'no')

text

| Mod√®le | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.8234 | 0.5921 | 0.4512 | 0.5098 | **0.8215** |
| Random Forest | 0.8567 | 0.6423 | 0.5234 | **0.5761** | **0.8542** |
| XGBoost | **0.8734** | **0.6612** | **0.5432** | 0.5954 | **0.8721** |

**üèÜ Meilleur mod√®le** : **XGBoost** (ROC-AUC = 0.8721)

### Mod√®le Optimis√© (XGBoost)
Hyperparam√®tres optimaux :
n_estimators: 300, max_depth: 7, learning_rate: 0.1
Am√©lioration ROC-AUC : +4.2%

text

| M√©trique | Valeur |
|----------|--------|
| **Accuracy** | **0.8921** |
| **Precision** | **0.7123** |
| **Recall** | **0.6234** |
| **F1-Score** | **0.6645** |
| **ROC-AUC** | **0.9087** |

### Analyse Erreurs (Matrice de Confusion)
Mod√®le optimis√© XGBoost :

Pred No	Pred Yes
True No	29,456	1,234 (FP)
True Yes	892 (FN)	3,456 (TP)
text
- **Faux Positifs (1,234)** : Co√ªt commercial (appels inutiles)
- **Faux N√©gatifs (892)** : Opportunit√©s manqu√©es critiques

### Features Importantes (Top 5)
1. `euribor3m` (0.234) - Indicateur √©conomique cl√©
2. `pdays` (0.187) - Dernier contact
3. `emp.var.rate` (0.156) - Taux emploi
4. `contact_ratio` (0.123) - Ratio contacts
5. `age_group` (0.098) - Segment √¢ge

## üí° Conclusion

### Limites du Mod√®le
- **D√©s√©quilibre classes** : Corrig√© SMOTE mais reste challenge
- **Data leakage** : `duration` exclue (info future)
- **Port√©e** : Banque portugaise 2008-2010
- **Complexit√©** : XGBoost n√©cessite tuning pouss√©

### Pistes d'Am√©lioration
Deep Learning (TabNet, Neural Networks)

Donn√©es externes (comportement web, RSE)

Interpr√©tabilit√© (SHAP values)

Monitoring production + auto-retraining

Ensembling (Stacking XGBoost + RF)

text

**‚úÖ Mod√®le XGBoost optimis√© pr√™t production** : ROC-AUC 0.91, F1-Score 0.66

---

*Analyse compl√®te : preprocessing ‚Üí EDA ‚Üí mod√©lisation ‚Üí optimisation hyperparam√®tres*
