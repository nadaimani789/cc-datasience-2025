{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1Oue9Uxs4X3Gfpv1eWq68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadaimani789/cc-datasience-2025/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "G_Xw9GJgz2HT",
        "outputId": "a15668de-6749-4361-f8d6-8379ea4b507a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aucun fichier trouvé automatiquement. Veuillez uploader votre fichier CSV ou ZIP contenant le dataset.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c945c026-9795-4094-a047-cf81c1a4d430\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c945c026-9795-4094-a047-cf81c1a4d430\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 0) Installer dépendances (décommenter si nécessaire)\n",
        "!pip install -q category_encoders xgboost shap joblib\n",
        "\n",
        "# 1) Imports\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import category_encoders as ce\n",
        "import joblib\n",
        "import shap\n",
        "\n",
        "# For Colab file upload\n",
        "try:\n",
        "    from google.colab import files\n",
        "    _IS_COLAB = True\n",
        "except Exception:\n",
        "    _IS_COLAB = False\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# ---------- 2) Chargement du dataset ----------\n",
        "# Le script tente plusieurs méthodes :\n",
        "# - chercher un fichier CSV local 'credit_scoring.csv' ou 'creditscoring-data.zip'\n",
        "# - sinon, proposer d'uploader le fichier via l'interface Colab\n",
        "\n",
        "def load_dataset():\n",
        "    possible_csv_names = ['credit_scoring.csv', 'creditscoring.csv', 'credit_scoring_data.csv', 'credit_scoring_data.csv', 'credit_scoring.csv', 'credit_scoring-data.csv']\n",
        "    # 1) chercher dans le répertoire courant\n",
        "    for name in possible_csv_names:\n",
        "        if os.path.exists(name):\n",
        "            print(f\"Chargement depuis le fichier local : {name}\")\n",
        "            return pd.read_csv(name, sep=';')\n",
        "    # 2) chercher zip mentionné (ex: creditscoring-data.zip)\n",
        "    zip_names = ['creditscoring-data.zip', 'credit_scoring.zip', 'creditscoring_data.zip']\n",
        "    for z in zip_names:\n",
        "        if os.path.exists(z):\n",
        "            print(f\"Extraction puis chargement depuis l'archive : {z}\")\n",
        "            with zipfile.ZipFile(z, 'r') as archive:\n",
        "                # trouver le premier csv dans l'archive\n",
        "                for f in archive.namelist():\n",
        "                    if f.lower().endswith('.csv'):\n",
        "                        print(f\"  -> lecture de {f} depuis l'archive\")\n",
        "                        with archive.open(f) as fh:\n",
        "                            return pd.read_csv(fh, sep=';')\n",
        "    # 3) si Colab, proposer upload\n",
        "    if _IS_COLAB:\n",
        "        print(\"Aucun fichier trouvé automatiquement. Veuillez uploader votre fichier CSV ou ZIP contenant le dataset.\")\n",
        "        uploaded = files.upload()\n",
        "        for fn in uploaded:\n",
        "            if fn.lower().endswith('.csv'):\n",
        "                print(f\"Chargé : {fn}\")\n",
        "                return pd.read_csv(io.BytesIO(uploaded[fn]), sep=';')\n",
        "            elif fn.lower().endswith('.zip'):\n",
        "                print(f\"Extraction depuis : {fn}\")\n",
        "                with zipfile.ZipFile(io.BytesIO(uploaded[fn]), 'r') as archive:\n",
        "                    for f in archive.namelist():\n",
        "                        if f.lower().endswith('.csv'):\n",
        "                            print(f\"  -> lecture de {f} depuis l'archive\")\n",
        "                            with archive.open(f) as fh:\n",
        "                                return pd.read_csv(fh, sep=';')\n",
        "    # 4) échec\n",
        "    raise FileNotFoundError(\"Aucun dataset trouvé. Déposez un fichier CSV/ZIP dans l'environnement ou nommez votre fichier 'credit_scoring.csv'.\")\n",
        "\n",
        "# Charge le dataset (exécuter)\n",
        "df = load_dataset()\n",
        "print(\"Taille du dataset :\", df.shape)\n",
        "display(df.head(5))\n",
        "\n",
        "# ---------- 3) Dictionnaire & exploration sommaire ----------\n",
        "def describe_dataset(df):\n",
        "    print(\"---- Aperçu des colonnes ----\")\n",
        "    display(pd.DataFrame({\n",
        "        'dtype': df.dtypes.astype(str),\n",
        "        'n_unique': df.nunique(),\n",
        "        'n_missing': df.isna().sum()\n",
        "    }))\n",
        "    print(\"\\nExemples de valeurs (quelques colonnes) :\")\n",
        "    display(df.iloc[:, :10].head())\n",
        "describe_dataset(df)\n",
        "\n",
        "# Trouver automatiquement la target probable (colonne 'default' si présente)\n",
        "if 'default' in df.columns:\n",
        "    target_col = 'default'\n",
        "else:\n",
        "    # heuristique : colonne contenant 'default' ou 'defaut' ou 'target' ou 'y'\n",
        "    candidates = [c for c in df.columns if any(x in c.lower() for x in ['default','defaut','target','y'])]\n",
        "    target_col = candidates[0] if candidates else None\n",
        "\n",
        "if target_col is None:\n",
        "    print(\"Aucune colonne target trouvée automatiquement. Merci de renommer la colonne target en 'default' ou indiquer le nom de la target dans le code.\")\n",
        "    # On arrête pour éviter erreurs\n",
        "    raise Exception(\"Target non trouvée. Renommez la colonne target en 'default' ou modifiez la variable target_col.\")\n",
        "else:\n",
        "    print(f\"Target détectée : '{target_col}'\")\n",
        "    # convertir target en binaire si besoin\n",
        "    if df[target_col].dtype == object:\n",
        "        # essayer mapping commun\n",
        "        df[target_col] = df[target_col].map({'yes':1,'no':0,'Y':1,'N':0,'Yes':1,'No':0}).fillna(df[target_col])\n",
        "    # forcer int\n",
        "    df[target_col] = pd.to_numeric(df[target_col], errors='coerce').fillna(0).astype(int)\n",
        "    print(df[target_col].value_counts())\n",
        "\n",
        "TARGET = target_col\n",
        "\n",
        "# ---------- 4) Pré-traitement initial ----------\n",
        "# 4.1 Nettoyage de base\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "# optionnel : supprimer colonnes id trop uniques (ex: customer_id)\n",
        "# garder une copie origine\n",
        "df_orig = df.copy()\n",
        "\n",
        "# 4.2 Séparer X / y et train-test split (stratifié)\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
        "print(\"Taille train:\", X_train.shape, \"Taille test:\", X_test.shape)\n",
        "print(\"Distribution target train:\\n\", y_train.value_counts(normalize=True))\n",
        "\n",
        "# 4.3 Identifier colonnes numériques et catégoriques\n",
        "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object','category', 'bool']).columns.tolist()\n",
        "\n",
        "# retirer colonnes avec trop de cardinalité si id (heuristique)\n",
        "# Exclure colonnes numériques qui sont en réalité des ids (toutes valeurs uniques)\n",
        "to_drop = []\n",
        "for col in numeric_cols:\n",
        "    if X_train[col].nunique() == X_train.shape[0]:\n",
        "        to_drop.append(col)\n",
        "if to_drop:\n",
        "    print(\"Colonnes identifiées comme ID (trop d'unicité) -> suppression :\", to_drop)\n",
        "    X_train = X_train.drop(columns=to_drop)\n",
        "    X_test = X_test.drop(columns=to_drop)\n",
        "    numeric_cols = [c for c in numeric_cols if c not in to_drop]\n",
        "\n",
        "# rafraîchir listes\n",
        "numeric_cols = [c for c in X_train.columns if pd.api.types.is_numeric_dtype(X_train[c])]\n",
        "cat_cols = [c for c in X_train.columns if c not in numeric_cols]\n",
        "\n",
        "print(\"Numériques:\", numeric_cols)\n",
        "print(\"Catégoriques:\", cat_cols)\n",
        "\n",
        "# ---------- 5) Feature Engineering (exemples génériques) ----------\n",
        "def add_basic_features(df):\n",
        "    df = df.copy()\n",
        "    # Exemple: si colonne 'loan_amount' et 'monthly_income' existent => debt_to_income\n",
        "    if 'loan_amount' in df.columns and 'monthly_income' in df.columns:\n",
        "        # éviter division par zéro\n",
        "        df['debt_to_income'] = df['loan_amount'] / (df['monthly_income'].replace({0: np.nan}))\n",
        "    # age groups\n",
        "    if 'age' in df.columns:\n",
        "        df['age_group'] = pd.cut(df['age'], bins=[0,25,35,50,70,120], labels=['<=25','26-35','36-50','51-70','70+'])\n",
        "    # Nb features null par observation\n",
        "    df['n_missing_row'] = df.isna().sum(axis=1)\n",
        "    return df\n",
        "\n",
        "X_train = add_basic_features(X_train)\n",
        "X_test = add_basic_features(X_test)\n",
        "\n",
        "# mettre à jour listes de colonnes\n",
        "numeric_cols = [c for c in X_train.columns if pd.api.types.is_numeric_dtype(X_train[c])]\n",
        "cat_cols = [c for c in X_train.columns if c not in numeric_cols]\n",
        "\n",
        "print(\"Après feature engineering, num:\", numeric_cols)\n",
        "print(\"Après feature engineering, cat:\", cat_cols)\n",
        "\n",
        "# ---------- 6) Pipeline de préprocessing ----------\n",
        "# Choix :\n",
        "# - pour numériques : IterativeImputer (MICE) + StandardScaler\n",
        "# - pour catégoriques : imputer constant + OneHotEncoder pour faibles cardinalités\n",
        "#   pour hautes cardinalités on utilisera TargetEncoder dans un pipeline séparé (category_encoders)\n",
        "\n",
        "# Séparer cat en low_card et high_card\n",
        "low_card = [c for c in cat_cols if X_train[c].nunique() <= 10]\n",
        "high_card = [c for c in cat_cols if X_train[c].nunique() > 10]\n",
        "\n",
        "print(\"Cat low_card:\", low_card)\n",
        "print(\"Cat high_card:\", high_card)\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('imputer', IterativeImputer(random_state=RANDOM_STATE, max_iter=10)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "lowcard_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "])\n",
        "\n",
        "# For high_card, use TargetEncoder (needs to be fit with y) -> handled in a custom pipeline below\n",
        "\n",
        "# ColumnTransformer for low-card categorical + numeric\n",
        "preprocessor_basic = ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_cols),\n",
        "    ('lowcat', lowcard_transformer, low_card)\n",
        "], remainder='drop', verbose_feature_names_out=False)\n",
        "\n",
        "# ---------- 7) Baseline model training function ----------\n",
        "def evaluate_model_with_target_encoder(model, X_train, y_train, X_test, y_test, random_state=RANDOM_STATE, use_calibration=False):\n",
        "    # We need to handle high_card columns via TargetEncoder fitted on train only\n",
        "    Xtr = X_train.copy()\n",
        "    Xte = X_test.copy()\n",
        "    if high_card:\n",
        "        te = ce.TargetEncoder(cols=high_card, smoothing=0.3)\n",
        "        te.fit(Xtr[high_card], y_train)\n",
        "        Xtr_he = te.transform(Xtr[high_card])\n",
        "        Xte_he = te.transform(Xte[high_card])\n",
        "        # drop original high_card and concat transformed\n",
        "        Xtr = pd.concat([Xtr.drop(columns=high_card), Xtr_he], axis=1)\n",
        "        Xte = pd.concat([Xte.drop(columns=high_card), Xte_he], axis=1)\n",
        "\n",
        "    # Preprocess basic (numeric + lowcard)\n",
        "    Xtr_prep = preprocessor_basic.fit_transform(Xtr)\n",
        "    Xte_prep = preprocessor_basic.transform(Xte)\n",
        "\n",
        "    # If OneHot created many cols, preprocessor_basic returns numpy array; that's fine\n",
        "    clf = model\n",
        "    if use_calibration:\n",
        "        clf = CalibratedClassifierCV(base_estimator=model, cv=3)\n",
        "\n",
        "    clf.fit(Xtr_prep, y_train)\n",
        "    y_pred = clf.predict(Xte_prep)\n",
        "    # some classifiers (CalibratedClassifierCV) may not have predict_proba for certain base estimators\n",
        "    try:\n",
        "        y_proba = clf.predict_proba(Xte_prep)[:,1]\n",
        "    except:\n",
        "        # fallback: decision_function then sigmoid\n",
        "        try:\n",
        "            scores = clf.decision_function(Xte_prep)\n",
        "            y_proba = (scores - scores.min()) / (scores.max() - scores.min())\n",
        "        except:\n",
        "            y_proba = np.zeros_like(y_pred, dtype=float)\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'f1': f1_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'roc_auc': roc_auc_score(y_test, y_proba),\n",
        "        'y_pred': y_pred,\n",
        "        'y_proba': y_proba,\n",
        "        'model': clf,\n",
        "        'Xte_prep': Xte_prep\n",
        "    }\n",
        "    return results\n",
        "\n",
        "# ---------- 8) Modèles testés : Logistic, RandomForest, XGBoost ----------\n",
        "# 8.1 LogisticRegression baseline\n",
        "print(\"\\n--- Entraînement : LogisticRegression (baseline) ---\")\n",
        "log_clf = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE)\n",
        "res_log = evaluate_model_with_target_encoder(log_clf, X_train, y_train, X_test, y_test)\n",
        "print(\"Logistic metrics:\", {k: round(v,4) for k,v in res_log.items() if k in ['accuracy','f1','precision','recall','roc_auc']})\n",
        "\n",
        "# 8.2 RandomForest baseline\n",
        "print(\"\\n--- Entraînement : RandomForest (baseline) ---\")\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
        "res_rf = evaluate_model_with_target_encoder(rf_clf, X_train, y_train, X_test, y_test)\n",
        "print(\"RandomForest metrics:\", {k: round(v,4) for k,v in res_rf.items() if k in ['accuracy','f1','precision','recall','roc_auc']})\n",
        "\n",
        "# 8.3 XGBoost baseline\n",
        "print(\"\\n--- Entraînement : XGBoost (baseline) ---\")\n",
        "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "res_xgb = evaluate_model_with_target_encoder(xgb_clf, X_train, y_train, X_test, y_test)\n",
        "print(\"XGBoost metrics:\", {k: round(v,4) for k,v in res_xgb.items() if k in ['accuracy','f1','precision','recall','roc_auc']})\n",
        "\n",
        "# ---------- 9) Cross-validation (StratifiedKFold) pour comparaison robuste ----------\n",
        "def cross_validate_pipeline(model, X, y, n_splits=5):\n",
        "    # We'll perform a custom CV that applies target encoding within each fold to avoid leakage\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    metrics = {'accuracy':[], 'f1':[], 'precision':[], 'recall':[], 'roc_auc':[]}\n",
        "    for train_idx, val_idx in skf.split(X, y):\n",
        "        Xtr, Xval = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
        "        ytr, yval = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        res = evaluate_model_with_target_encoder(model, Xtr, ytr, Xval, yval)\n",
        "        for m in metrics:\n",
        "            metrics[m].append(res[m])\n",
        "    return {m: np.mean(metrics[m]) for m in metrics}\n",
        "\n",
        "print(\"\\n--- Cross-validation 5-fold (estimation) ---\")\n",
        "print(\"Logistic CV:\", cross_validate_pipeline(log_clf, X_train, y_train))\n",
        "print(\"RF CV:\", cross_validate_pipeline(rf_clf, X_train, y_train))\n",
        "print(\"XGB CV:\", cross_validate_pipeline(xgb_clf, X_train, y_train))\n",
        "\n",
        "# ---------- 10) Hyperparam tuning (RandomizedSearchCV) pour RandomForest et XGBoost ----------\n",
        "# NOTE: nous faisons une recherche en pipeline simplifiée (target encoding done inside fit function not directly compatible with sklearn CV),\n",
        "# donc nous allons tuner sur processed numpy arrays using full-train target encoding (approx) or use sklearn-compatible wrappers.\n",
        "# Pour simplifier et être reproductible : nous encoderons high-card cat with TargetEncoder on whole train (acceptable but not ideal).\n",
        "# Ensuite RandomizedSearch sur pipeline contenant preprocessor_basic and model.\n",
        "\n",
        "# Préparer X_train_enc, X_test_enc une fois (target-encoding sur train)\n",
        "def prepare_encoded_arrays(X_train, y_train, X_test):\n",
        "    Xtr = X_train.copy()\n",
        "    Xte = X_test.copy()\n",
        "    if high_card:\n",
        "        te = ce.TargetEncoder(cols=high_card, smoothing=0.3)\n",
        "        te.fit(Xtr[high_card], y_train)\n",
        "        Xtr_he = te.transform(Xtr[high_card])\n",
        "        Xte_he = te.transform(Xte[high_card])\n",
        "        Xtr = pd.concat([Xtr.drop(columns=high_card), Xtr_he], axis=1)\n",
        "        Xte = pd.concat([Xte.drop(columns=high_card), Xte_he], axis=1)\n",
        "    Xtr_p = preprocessor_basic.fit_transform(Xtr)\n",
        "    Xte_p = preprocessor_basic.transform(Xte)\n",
        "    return Xtr_p, Xte_p\n",
        "\n",
        "print(\"\\nPréparation des arrays encodés pour tuning (target-encoding sur train)...\")\n",
        "Xtr_p, Xte_p = prepare_encoded_arrays(X_train, y_train, X_test)\n",
        "\n",
        "# 10.1 RandomForest RandomizedSearch\n",
        "from scipy.stats import randint, uniform\n",
        "rf_param_dist = {\n",
        "    'n_estimators': [100,200,400],\n",
        "    'max_depth': [None, 6, 10, 20],\n",
        "    'min_samples_split': [2,5,10],\n",
        "    'min_samples_leaf': [1,2,4],\n",
        "}\n",
        "print(\"Recherche hyperparamètres RandomForest (RandomizedSearch)\")\n",
        "rf_base = RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
        "rs_rf = RandomizedSearchCV(rf_base, rf_param_dist, n_iter=20, scoring='roc_auc', cv=3, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "rs_rf.fit(Xtr_p, y_train)\n",
        "print(\"Meilleurs params RF:\", rs_rf.best_params_)\n",
        "best_rf = rs_rf.best_estimator_\n",
        "y_proba_rf = best_rf.predict_proba(Xte_p)[:,1]\n",
        "print(\"RF test ROC-AUC:\", round(roc_auc_score(y_test, y_proba_rf),4))\n",
        "\n",
        "# 10.2 XGBoost RandomizedSearch\n",
        "xgb_param_dist = {\n",
        "    'n_estimators': [100,200,400],\n",
        "    'max_depth': [3,6,10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.6,0.8,1.0],\n",
        "    'colsample_bytree': [0.6,0.8,1.0]\n",
        "}\n",
        "print(\"Recherche hyperparamètres XGBoost (RandomizedSearch)\")\n",
        "xgb_base = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "rs_xgb = RandomizedSearchCV(xgb_base, xgb_param_dist, n_iter=25, scoring='roc_auc', cv=3, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "rs_xgb.fit(Xtr_p, y_train)\n",
        "print(\"Meilleurs params XGB:\", rs_xgb.best_params_)\n",
        "best_xgb = rs_xgb.best_estimator_\n",
        "y_proba_xgb = best_xgb.predict_proba(Xte_p)[:,1]\n",
        "print(\"XGB test ROC-AUC:\", round(roc_auc_score(y_test, y_proba_xgb),4))\n",
        "\n",
        "# 10.3 LogisticRegression tuning (C)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "log_param_grid = {'C':[0.01,0.1,1,10,100]}\n",
        "log_pipe = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE)\n",
        "gs_log = GridSearchCV(log_pipe, log_param_grid, scoring='roc_auc', cv=3, n_jobs=-1)\n",
        "gs_log.fit(Xtr_p, y_train)\n",
        "best_log = gs_log.best_estimator_\n",
        "y_proba_log = best_log.predict_proba(Xte_p)[:,1]\n",
        "print(\"Log best C:\", gs_log.best_params_, \"ROC-AUC:\", round(roc_auc_score(y_test, y_proba_log),4))\n",
        "\n",
        "# ---------- 11) Évaluation finale & rapports ----------\n",
        "def print_eval(y_true, y_pred, y_proba, model_name=\"model\"):\n",
        "    print(f\"\\n--- Évaluation: {model_name} ---\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred),4))\n",
        "    print(\"Precision:\", round(precision_score(y_true, y_pred),4))\n",
        "    print(\"Recall:\", round(recall_score(y_true, y_pred),4))\n",
        "    print(\"F1:\", round(f1_score(y_true, y_pred),4))\n",
        "    print(\"ROC-AUC:\", round(roc_auc_score(y_true, y_proba),4))\n",
        "    print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Matrice de confusion - {model_name}\")\n",
        "    plt.xlabel(\"Pred\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "    # ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    roc_auc_val = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_val:.4f}\")\n",
        "    plt.plot([0,1],[0,1],'k--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC - {model_name}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    # Precision-Recall\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
        "    pr_auc = auc(rec, prec)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(rec, prec, label=f\"PR AUC = {pr_auc:.4f}\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"Precision-Recall - {model_name}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Évaluer best models (sur Xte_p préparé)\n",
        "y_pred_rf = best_rf.predict(Xte_p)\n",
        "y_proba_rf = best_rf.predict_proba(Xte_p)[:,1]\n",
        "print_eval(y_test, y_pred_rf, y_proba_rf, \"RandomForest (tuned)\")\n",
        "\n",
        "y_pred_xgb = best_xgb.predict(Xte_p)\n",
        "y_proba_xgb = best_xgb.predict_proba(Xte_p)[:,1]\n",
        "print_eval(y_test, y_pred_xgb, y_proba_xgb, \"XGBoost (tuned)\")\n",
        "\n",
        "y_pred_log = best_log.predict(Xte_p)\n",
        "y_proba_log = best_log.predict_proba(Xte_p)[:,1]\n",
        "print_eval(y_test, y_pred_log, y_proba_log, \"LogisticRegression (tuned)\")\n",
        "\n",
        "# ---------- 12) Interprétabilité : importances + SHAP (pour XGBoost si disponible) ----------\n",
        "def show_feature_importance(model, X_processed, feature_names=None, top_n=20):\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        imp = model.feature_importances_\n",
        "        if feature_names is None:\n",
        "            feature_names = [f\"f{i}\" for i in range(len(imp))]\n",
        "        df_imp = pd.DataFrame({'feature':feature_names, 'importance':imp}).sort_values('importance', ascending=False).head(top_n)\n",
        "        plt.figure(figsize=(8,6))\n",
        "        sns.barplot(data=df_imp, x='importance', y='feature')\n",
        "        plt.title(\"Feature importances\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Le modèle n'a pas d'attribut feature_importances_.\")\n",
        "\n",
        "# essayer obtenir feature names (preprocessor_basic crée numpy arrays)\n",
        "# construire feature names approximatives\n",
        "def get_feature_names_from_preprocessor(preprocessor, X_sample):\n",
        "    # numeric names + onehot categories\n",
        "    num_names = numeric_cols\n",
        "    cat_names = []\n",
        "    if low_card:\n",
        "        # get onehot names\n",
        "        ohe = preprocessor.named_transformers_.get('lowcat').named_steps['onehot']\n",
        "        try:\n",
        "            categories = ohe.categories_\n",
        "            for i, catcol in enumerate(low_card):\n",
        "                for c in categories[i]:\n",
        "                    cat_names.append(f\"{catcol}__{c}\")\n",
        "        except:\n",
        "            # fallback\n",
        "            cat_names += low_card\n",
        "    return num_names + cat_names\n",
        "\n",
        "feature_names = get_feature_names_from_preprocessor(preprocessor_basic, X_train)\n",
        "print(\"Noms features approximatifs (extrait):\", feature_names[:30])\n",
        "\n",
        "print(\"\\nImportances RF (tuned):\")\n",
        "show_feature_importance(best_rf, Xtr_p, feature_names=feature_names)\n",
        "\n",
        "# SHAP for XGBoost (peut être lent)\n",
        "try:\n",
        "    print(\"\\nCalcul des valeurs SHAP pour XGBoost (peut prendre du temps)...\")\n",
        "    explainer = shap.TreeExplainer(best_xgb)\n",
        "    shap_values = explainer.shap_values(Xtr_p)\n",
        "    shap.summary_plot(shap_values, Xtr_p, feature_names=feature_names, show=True)\n",
        "except Exception as e:\n",
        "    print(\"SHAP échoué ou trop lent dans cet environnement:\", e)\n",
        "\n",
        "# ---------- 13) Calibration & sauvegarde du modèle final ----------\n",
        "# Exemple : calibrer le meilleur modèle si nécessaire (ici XGBoost)\n",
        "calibrated = CalibratedClassifierCV(best_xgb, cv=3)\n",
        "calibrated.fit(Xtr_p, y_train)\n",
        "y_proba_cal = calibrated.predict_proba(Xte_p)[:,1]\n",
        "print(\"XGB calibré ROC-AUC:\", round(roc_auc_score(y_test, y_proba_cal),4))\n",
        "\n",
        "# Sauvegarder préprocesseur (encoders) + best model\n",
        "# On sauvegarde : preprocessor_basic (fit), target encoder (if used), and model\n",
        "# Pour simplicité, on sauvegarde les objets suivants :\n",
        "artifacts = {}\n",
        "# sauvegarder preprocessor_basic (déjà fit)\n",
        "artifacts['preprocessor_basic'] = preprocessor_basic\n",
        "if high_card:\n",
        "    # sauvegarder target encoder entrainé sur tout train\n",
        "    te_final = ce.TargetEncoder(cols=high_card, smoothing=0.3)\n",
        "    te_final.fit(X_train[high_card], y_train)\n",
        "    artifacts['target_encoder'] = te_final\n",
        "# sauvegarder model calibré\n",
        "artifacts['model'] = calibrated\n",
        "\n",
        "joblib.dump(artifacts, 'credit_model_artifacts.joblib')\n",
        "print(\"Artifacts sauvegardés dans 'credit_model_artifacts.joblib'\")\n",
        "\n",
        "# Si Colab => proposer téléchargement\n",
        "if _IS_COLAB:\n",
        "    try:\n",
        "        files.download('credit_model_artifacts.joblib')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# ---------- 14) Résumé final et suggestions pour le rapport ----------\n",
        "print(\"\"\"\n",
        "--- FIN du script ---\n",
        "Résumé :\n",
        " - 3 modèles testés : LogisticRegression, RandomForest, XGBoost.\n",
        " - Hyperparam tuning réalisé pour RF et XGB (RandomizedSearch).\n",
        " - Évaluations affichées (ROC-AUC, F1, matrice de confusion, courbes).\n",
        " - Artifacts sauvegardés : préprocesseur, target encoder (si présent), modèle calibré.\n",
        "\n",
        "Suggestions pour le rapport scientifique (à inclure):\n",
        " - Décrire le dataset : taille, variables, target.\n",
        " - Justifier les choix d'imputation (IterativeImputer), d'encodage (OneHot vs TargetEncoding).\n",
        " - Expliquer la stratégie de validation (StratifiedKFold).\n",
        " - Présenter les métriques clés (ROC-AUC, F1, recall) et discuter des faux négatifs.\n",
        " - Limites : fuite de données possible si TargetEncoding mal appliqué (éviter d'encoder sur l'ensemble).\n",
        " - Pistes d'amélioration : collecte features comportementales, pipeline complet sklearn-compatible, calibrage des probabilités, tests coûts/avantages business.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "2cf2b6b1",
        "outputId": "3fa724b2-f98a-4845-d369-0e6d17f2b9fc"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_name = 'bank.csv'\n",
        "\n",
        "if os.path.exists(file_name):\n",
        "    print(f\"Tentative de chargement du fichier '{file_name}' pour vérifier le délimiteur...\")\n",
        "    try:\n",
        "        # Tentative de chargement avec point-virgule\n",
        "        df_bank = pd.read_csv(file_name, sep=';')\n",
        "        if df_bank.shape[1] > 1: # Si plus d'une colonne, le délimiteur est probablement correct\n",
        "            print(f\"'{file_name}' chargé avec succès en utilisant le délimiteur ';'. Forme: {df_bank.shape}\")\n",
        "            display(df_bank.head())\n",
        "        else:\n",
        "            print(f\"'{file_name}' chargé avec délimiteur ';' a résulté en {df_bank.shape[1]} colonne. Essai avec délimiteur ','.\")\n",
        "            # Tentative de chargement avec virgule\n",
        "            df_bank = pd.read_csv(file_name, sep=',')\n",
        "            if df_bank.shape[1] > 1:\n",
        "                print(f\"'{file_name}' chargé avec succès en utilisant le délimiteur ','. Forme: {df_bank.shape}\")\n",
        "                display(df_bank.head())\n",
        "            else:\n",
        "                print(f\"'{file_name}' chargé avec le délimiteur ',' a également résulté en {df_bank.shape[1]} colonne. Inspection manuelle nécessaire.\")\n",
        "                display(df_bank.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du chargement de '{file_name}': {e}\")\n",
        "else:\n",
        "    print(f\"Le fichier '{file_name}' n'a pas été trouvé dans le répertoire courant. Veuillez vous assurer qu'il est téléchargé.\")\n",
        "\n",
        "# Si le fichier 'bank.csv' est le fichier principal que vous souhaitez utiliser,\n",
        "# vous devrez peut-être réexécuter la cellule de chargement du dataset (section 2)\n",
        "# ou adapter le code pour utiliser `df_bank` à la place de `df`.\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tentative de chargement du fichier 'bank.csv' pour vérifier le délimiteur...\n",
            "'bank.csv' chargé avec succès en utilisant le délimiteur ';'. Forme: (4521, 17)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   age          job  marital  education default  balance housing loan  \\\n",
              "0   30   unemployed  married    primary      no     1787      no   no   \n",
              "1   33     services  married  secondary      no     4789     yes  yes   \n",
              "2   35   management   single   tertiary      no     1350     yes   no   \n",
              "3   30   management  married   tertiary      no     1476     yes  yes   \n",
              "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
              "\n",
              "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
              "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
              "1  cellular   11   may       220         1    339         4  failure  no  \n",
              "2  cellular   16   apr       185         1    330         1  failure  no  \n",
              "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
              "4   unknown    5   may       226         1     -1         0  unknown  no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6aa8881-7e9f-40c9-b184-b64b6b7cfa11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>married</td>\n",
              "      <td>primary</td>\n",
              "      <td>no</td>\n",
              "      <td>1787</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>19</td>\n",
              "      <td>oct</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>4789</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>cellular</td>\n",
              "      <td>11</td>\n",
              "      <td>may</td>\n",
              "      <td>220</td>\n",
              "      <td>1</td>\n",
              "      <td>339</td>\n",
              "      <td>4</td>\n",
              "      <td>failure</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>management</td>\n",
              "      <td>single</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>1350</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>16</td>\n",
              "      <td>apr</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>330</td>\n",
              "      <td>1</td>\n",
              "      <td>failure</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>1476</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>199</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6aa8881-7e9f-40c9-b184-b64b6b7cfa11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6aa8881-7e9f-40c9-b184-b64b6b7cfa11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6aa8881-7e9f-40c9-b184-b64b6b7cfa11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-be5b71ed-7a87-474b-913f-1f09b8d9f194\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be5b71ed-7a87-474b-913f-1f09b8d9f194')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-be5b71ed-7a87-474b-913f-1f09b8d9f194 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# ou adapter le code pour utiliser `df_bank` \\u00e0 la place de `df`\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 30,\n        \"max\": 59,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          33,\n          59,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"services\",\n          \"blue-collar\",\n          \"unemployed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"single\",\n          \"married\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"primary\",\n          \"secondary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1764,\n        \"min\": 0,\n        \"max\": 4789,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"unknown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 3,\n        \"max\": 19,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"may\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 79,\n        \"max\": 226,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          220\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 183,\n        \"min\": -1,\n        \"max\": 339,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"poutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"failure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}